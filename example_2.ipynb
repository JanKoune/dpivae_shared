{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7003c0f-f1ad-4989-a159-5e9141f28d9a",
   "metadata": {},
   "source": [
    "## Example 2: Variational autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf3b6db-dc8f-47f3-81ef-cece17a84431",
   "metadata": {},
   "source": [
    "### Environment setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616606ce-8cd9-4613-ba87-ac74f41efaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/JanKoune/dpivae_shared.git\n",
    "%cd dpivae_shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b673a76-9195-41d4-8cde-700846212b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "from torch import nn, optim\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import seaborn as sns\n",
    "\n",
    "from models.nn import MLP\n",
    "from models.encoders import AmortizedGaussianEncoder\n",
    "from models.decoders import GaussianDecoder\n",
    "from models.vae import VariationalInference\n",
    "from utils.transforms import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d827106e-1997-4de4-b657-43a93a1dcd1c",
   "metadata": {},
   "source": [
    "### Problem setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae099227-2bee-40b9-82ea-b0b779f17a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(123)\n",
    "n_train = 1024\n",
    "n_batch = 32\n",
    "nd_physics = 32\n",
    "n_iter = 20_000\n",
    "n_mc = 64\n",
    "n_plot = 5_000\n",
    "\n",
    "# Parameters\n",
    "nz_full = 4\n",
    "nz_part = 2\n",
    "nz_data = 4\n",
    "\n",
    "# NN settings\n",
    "layers_nn_full = [256, 64]\n",
    "layers_nn_part = [256, 64]\n",
    "layers_nn_data = [256]\n",
    "\n",
    "# Surrogate models\n",
    "model_path = \"./trained_models/\"\n",
    "\n",
    "# Optimization\n",
    "lr_vae = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a2a52b-928b-4b49-bf5e-f404c0499791",
   "metadata": {},
   "source": [
    "### Beam example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a92ba-75f5-4c69-947c-1e8c4b6304a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain\n",
    "v_min, v_max = 0.00001, 1.0\n",
    "v = torch.linspace(v_min, v_max, nd_physics)\n",
    "\n",
    "# Noise\n",
    "sigma_p = torch.tensor(0.2)\n",
    "\n",
    "# Indices of entries of X corresponding to each effect\n",
    "z_idx_p = [0, 1]\n",
    "z_idx_d = [2, 3]\n",
    "idx_obs = [False, True]\n",
    "latent_groups = [z_idx_p, z_idx_d]\n",
    "param_labels = [r\"$E \\ [Pa]$\", r\"$x_F [m]$\", r\"$\\mathrm{log}k_v [N/m]$\", r\"$T [C^o]$\"]\n",
    "\n",
    "mu_prior = torch.tensor([4.0, 0.5, 8.0, -4.0])\n",
    "sigma_prior = torch.tensor([0.5, 0.1, 1.0, 3.0])\n",
    "\n",
    "mu_gt = mu_prior\n",
    "sigma_gt = 0.7 * sigma_prior\n",
    "\n",
    "# Priors of physics-based latent variables\n",
    "mu_hybrid_prior = torch.cat((mu_prior[z_idx_p], torch.zeros(nz_data)))\n",
    "sigma_hybrid_prior = torch.cat((sigma_prior[z_idx_p], torch.ones(nz_data)))\n",
    "dist_hybrid_prior = dist.Normal(mu_hybrid_prior, sigma_hybrid_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d2920-c5a8-4108-92f7-e57f08c8cc3b",
   "metadata": {},
   "source": [
    "### Load data and surrogates of physics-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488bd29-50ff-43ba-a8a3-bd6223de54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data, interpolate y\n",
    "X_full_load = torch.load(\"./data/X_beam.pt\")\n",
    "y_full_load = torch.load(\"./data/y_beam.pt\")\n",
    "X_part_load = torch.load(\"./data/X_beam_partial.pt\")\n",
    "y_part_load = torch.load(\"./data/y_beam_partial.pt\")\n",
    "\n",
    "# Load X\n",
    "X_full = X_full_load[1:]\n",
    "X_part = X_part_load[1:]\n",
    "\n",
    "y_full_raw = y_full_load[1:]\n",
    "y_part_raw = y_part_load[1:]\n",
    "coords = y_full_load[0]\n",
    "\n",
    "# Interpolate y\n",
    "f_full = scipy.interpolate.interp1d(coords.numpy(), y_full_raw.numpy())\n",
    "f_part = scipy.interpolate.interp1d(coords.numpy(), y_part_raw.numpy())\n",
    "y_full = torch.tensor(f_full(v.numpy()))\n",
    "y_part = torch.tensor(f_part(v.numpy()))\n",
    "\n",
    "# Scaling\n",
    "X_scaler_full = StandardScaler()\n",
    "X_scaler_full = X_scaler_full.fit(X_full)\n",
    "\n",
    "X_scaler_part = StandardScaler()\n",
    "X_scaler_part = X_scaler_part.fit(X_part)\n",
    "\n",
    "# loss\n",
    "loss_fn_train = nn.MSELoss()\n",
    "loss_fn_test = nn.MSELoss()\n",
    "\n",
    "# Models\n",
    "full_model = MLP(\n",
    "    nz_full,\n",
    "    nd_physics,\n",
    "    layers_nn_full,\n",
    "    input_transform=X_scaler_full,\n",
    "    nonlinear_last=None,\n",
    ")\n",
    "\n",
    "part_model = MLP(\n",
    "    nz_part,\n",
    "    nd_physics,\n",
    "    layers_nn_part,\n",
    "    input_transform=X_scaler_part,\n",
    "    nonlinear_last=None,\n",
    ")\n",
    "\n",
    "data_model = MLP(\n",
    "    nz_data,\n",
    "    nd_physics,\n",
    "    layers_nn_data,\n",
    "    nonlinear_last=None,\n",
    ")\n",
    "\n",
    "# Load pre-trained surrogates\n",
    "full_model.load_state_dict(torch.load(model_path + \"full_model\"))\n",
    "full_model.eval()\n",
    "\n",
    "# Load pre-trained surrogates\n",
    "part_model.load_state_dict(torch.load(model_path + \"part_model\"))\n",
    "part_model.eval()\n",
    "\n",
    "# Freeze models\n",
    "for param in full_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Freeze models\n",
    "for param in part_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77faacdd-80ed-4855-bb6d-db36b000a378",
   "metadata": {},
   "source": [
    "### Synthetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d61dfa-e9df-4e2a-b26d-f8ebefdf9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample inputs and outputs from the ground truth\n",
    "def generate_synthetic_data(n):\n",
    "    z_gt_sample = dist.Normal(mu_gt, sigma_gt).sample((n,))\n",
    "    x_sample = full_model(z_gt_sample)\n",
    "    x_sample += dist.Normal(0.0, sigma_p).sample(x_sample.shape)\n",
    "    return z_gt_sample, x_sample\n",
    "\n",
    "z_gt, x_meas = generate_synthetic_data(n_train)\n",
    "z_gt_plot, x_meas_plot = generate_synthetic_data(n_plot)\n",
    "x_meas_plot_mean = x_meas_plot.mean(dim=0).detach()\n",
    "x_meas_plot_std = x_meas_plot.std(dim=0).detach()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(v, x_meas.T.detach().numpy(), color=\"blue\", linewidth=1.0, alpha=0.2)\n",
    "plt.plot(v, x_meas_plot_mean, color=\"red\")\n",
    "plt.fill_between(v, x_meas_plot_mean - 2 * x_meas_plot_std, x_meas_plot_mean + 2 * x_meas_plot_std, alpha=0.2, color=\"red\")\n",
    "plt.grid()\n",
    "plt.title(\"Measurements\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b195ed-9023-4c4c-a499-9d5d1d85efc0",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaaf45b-0c9e-4076-bab7-a5692c5f6abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = AmortizedGaussianEncoder(\n",
    "    n_latent=nz_part + nz_data,\n",
    "    n_dim=nd_physics,\n",
    "    mean_layers=[128],\n",
    "    sigma_layers=[128],\n",
    "    cov_layers=[128],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf3aae-abaf-4c64-905b-bd3003d7897d",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1e1416-49df-4668-a53b-b07c88ecd211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, phys_model, nn_model):\n",
    "        super().__init__()\n",
    "        self.phys_model = phys_model\n",
    "        self.nn_model = nn_model\n",
    "    def forward(self, z):\n",
    "        z_phys = z[..., 0:nz_part]\n",
    "        z_data = z[..., nz_part:(nz_part + nz_data)]\n",
    "        return self.phys_model(z_phys) + self.nn_model(z_data)\n",
    "\n",
    "hybrid_model = HybridModel(part_model, data_model)\n",
    "\n",
    "# Response physics-driven decoder\n",
    "decoder = GaussianDecoder(hybrid_model, sigma=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2780ab0-8be0-42ff-ba57-7c2301dfa5f2",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2bd5c-eef8-4499-ab91-906b8f500b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalInference(\n",
    "    encoder,\n",
    "    decoder,\n",
    "    dist_hybrid_prior,\n",
    "    jitter=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705fcf79-cad2-4887-9d71-2a4f7feab511",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ea4f5-0345-4a3f-88b2-1dac8ea6f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vec = []\n",
    "optimizer = optim.Adam(vae.parameters(), lr=lr_vae)\n",
    "\n",
    "pbar = trange(n_iter)\n",
    "for idx in pbar:\n",
    "    optimizer.zero_grad()\n",
    "    sample_idx = torch.multinomial(torch.ones(n_train), n_batch, replacement=False)\n",
    "    x_i = x_meas[sample_idx, :]\n",
    "    loss_full = vae.loss(x_i, n=n_mc).sum() / (n_batch * nd_physics)\n",
    "    loss_full.backward()\n",
    "    optimizer.step()\n",
    "    if idx % 100 == 0:\n",
    "        pbar.set_postfix(ELBO=loss_full.detach(), refresh=True)\n",
    "    loss_vec.append(loss_full.detach())\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(0, n_iter), loss_vec, label=\"loss\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b435f2-56c8-4542-9c03-fb55de595759",
   "metadata": {},
   "source": [
    "### Vizualize predictions and latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a80abe-a6ab-40d7-aefc-4f57e6710c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualization parameters\n",
    "n_interp = 5\n",
    "alpha_plot = torch.tensor(0.99)\n",
    "cmap_name = \"plasma\"\n",
    "\n",
    "# Plot interpolation of the response across the latent space\n",
    "c_interp = mpl.colormaps[cmap_name](np.linspace(0.0, 1.0, n_interp))\n",
    "fig_pred, ax_pred = plt.subplots(3, 4, figsize=(12, 9), sharex=\"col\", layout=\"compressed\")\n",
    "\n",
    "# Linear interpolation across a dimension of the latent space while keeping\n",
    "# the remaining latent variables equal to the ground truth mean\n",
    "for idx_z_interp in range(4):\n",
    "\n",
    "    # Interpolate z\n",
    "    z_interp = torch.linspace(\n",
    "        mu_gt[idx_z_interp] - 3.0 * sigma_gt[idx_z_interp],\n",
    "        mu_gt[idx_z_interp] + 3.0 * sigma_gt[idx_z_interp],\n",
    "        n_interp,\n",
    "    )\n",
    "    z_gt_interp = mu_gt.repeat(n_interp, 1)\n",
    "    z_gt_interp[:, idx_z_interp] = z_interp\n",
    "    z_idx_obs = np.array(z_idx_d)[np.array(idx_obs)]\n",
    "    z_idx_nobs = np.array(z_idx_d)[np.logical_not(np.array(idx_obs))]\n",
    "\n",
    "    # Generate synthetic data\n",
    "    x_interp = full_model(z_gt_interp)\n",
    "    x_interp += dist.Normal(0.0, sigma_p).sample(x_interp.shape)\n",
    "\n",
    "    # VAE prediction\n",
    "    x_pred, z_post, dens_z_post = vae.forward(x_interp, n=n_plot)\n",
    "    x_pred_phys = part_model(z_post[..., 0:nz_part])\n",
    "    x_pred_data = data_model(z_post[..., nz_part:(nz_part + nz_data)])\n",
    "\n",
    "    # Get means and std. devs.\n",
    "    mean_pred = torch.mean(x_pred, dim=0).detach()\n",
    "    sigma_pred = torch.std(x_pred, dim=0).detach()\n",
    "\n",
    "    mean_pred_phys = torch.mean(x_pred_phys, dim=0).detach()\n",
    "    sigma_pred_phys = torch.std(x_pred_phys, dim=0).detach()\n",
    "\n",
    "    mean_pred_data = torch.mean(x_pred_data, dim=0).detach()\n",
    "    sigma_pred_data = torch.std(x_pred_data, dim=0).detach()\n",
    "\n",
    "    # Create colorbar for the current latent variable\n",
    "    norm_bar = Normalize(vmin=z_interp[0], vmax=z_interp[-1])\n",
    "    cmap_bar = LinearSegmentedColormap.from_list(cmap_name, c_interp, N=n_interp)\n",
    "    smap_bar = ScalarMappable(norm_bar, cmap=cmap_bar)\n",
    "\n",
    "    for i in range(n_interp):\n",
    "\n",
    "        # Physics-based model prediction\n",
    "        ax_pred[0, idx_z_interp].plot(\n",
    "            v,\n",
    "            mean_pred_phys[i],\n",
    "            alpha=0.5,\n",
    "            color=c_interp[i],\n",
    "            label=param_labels[idx_z_interp] + r\"$={:.3f}$\".format(z_interp[i]),\n",
    "        )\n",
    "        ax_pred[0, idx_z_interp].fill_between(\n",
    "            v,\n",
    "            mean_pred_phys[i] - 2.0 * sigma_pred_phys[i],\n",
    "            mean_pred_phys[i] + 2.0 * sigma_pred_phys[i],\n",
    "            alpha=0.5,\n",
    "            color=c_interp[i],\n",
    "        )\n",
    "\n",
    "        # Data driven model prediction\n",
    "        ax_pred[1, idx_z_interp].plot(\n",
    "            v,\n",
    "            mean_pred_data[i],\n",
    "            alpha=0.5,\n",
    "            color=c_interp[i],\n",
    "            label=param_labels[idx_z_interp] + r\"$={:.3f}$\".format(z_interp[i]),\n",
    "        )\n",
    "        ax_pred[1, idx_z_interp].fill_between(\n",
    "            v,\n",
    "            mean_pred_data[i] - 2.0 * sigma_pred_data[i],\n",
    "            mean_pred_data[i] + 2.0 * sigma_pred_data[i],\n",
    "            alpha=0.5,\n",
    "            color=c_interp[i],\n",
    "        )\n",
    "\n",
    "        # Hybrid model prediction\n",
    "        ax_pred[2, idx_z_interp].plot(\n",
    "            v,\n",
    "            mean_pred[i],\n",
    "            alpha=0.5,\n",
    "            color=c_interp[i],\n",
    "            label=param_labels[idx_z_interp] + r\"$={:.3f}$\".format(z_interp[i]),\n",
    "        )\n",
    "        ax_pred[2, idx_z_interp].fill_between(\n",
    "            v,\n",
    "            mean_pred[i] - 2.0 * sigma_pred[i],\n",
    "            mean_pred[i] + 2.0 * sigma_pred[i],\n",
    "            alpha=0.5,\n",
    "            color=c_interp[i],\n",
    "        )\n",
    "\n",
    "        # Plot measurements\n",
    "        ax_pred[2, idx_z_interp].scatter(v, x_interp[i].detach(), color=c_interp[i])\n",
    "\n",
    "    ax_pred[0, idx_z_interp].grid()\n",
    "    ax_pred[1, idx_z_interp].grid()\n",
    "    ax_pred[2, idx_z_interp].grid()\n",
    "\n",
    "    ax_pred[2, idx_z_interp].set_xlabel(\"X-position [m]\", fontsize=16)\n",
    "    cbar_pred = fig_pred.colorbar(\n",
    "        smap_bar, ax=ax_pred[0, idx_z_interp], orientation=\"horizontal\", location=\"top\"\n",
    "    )\n",
    "    cbar_pred.set_label(label=param_labels[idx_z_interp], size=18)\n",
    "    cbar_pred.ax.tick_params(labelsize=12)\n",
    "\n",
    "ax_pred[0, 0].set_ylabel(\"Physics-based pred. [m]\", fontsize=18)\n",
    "ax_pred[1, 0].set_ylabel(\"Data-driven pred. [m]\", fontsize=18)\n",
    "ax_pred[2, 0].set_ylabel(\"Combined pred. [m]\", fontsize=18)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
