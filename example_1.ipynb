{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c03b1f4b-7eea-435b-bff1-d7ec1b2b2f2f",
   "metadata": {},
   "source": [
    "## Example 1: Variational inference under full and partially specified physics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54509e38-1aad-42f7-8d9f-7954169ecc5c",
   "metadata": {},
   "source": [
    "### Environment setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f795ce-0bd0-481b-bfd5-885758fa569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/JanKoune/dpivae_shared.git\n",
    "%cd dpivae_shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b76a7-b0f2-465b-8e38-420e85ffb4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "from torch import nn, optim\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from models.nn import MLP\n",
    "from models.encoders import GaussianEncoder\n",
    "from models.decoders import GaussianDecoder\n",
    "from models.vae import VariationalInference\n",
    "from utils.transforms import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741c99c-f466-470e-bc77-db3baf598d4a",
   "metadata": {},
   "source": [
    "### Model and optimization settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38530fe-f17d-458b-8ddb-3f105066e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(123)\n",
    "n_data = 2\n",
    "nd_physics = 32\n",
    "n_iter = 25_000\n",
    "n_mc = 128\n",
    "n_plot = 5_000\n",
    "\n",
    "# Parameters\n",
    "nz_full = 4\n",
    "nz_part = 2\n",
    "nz_data = 4\n",
    "\n",
    "# NN settings\n",
    "layers_nn_full = [256, 64]\n",
    "layers_nn_part = [256, 64]\n",
    "\n",
    "# Surrogate models\n",
    "model_path = \"./trained_models/\"\n",
    "\n",
    "# Optimization\n",
    "lr_vi = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e4767e-0f1e-4bc4-8e07-2d030662d8eb",
   "metadata": {},
   "source": [
    "### Problem setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f2458-26f9-470e-a03c-c9defdcc37eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain\n",
    "v_min, v_max = 0.00001, 1.0\n",
    "v = torch.linspace(v_min, v_max, nd_physics)\n",
    "\n",
    "# Noise\n",
    "sigma_meas = torch.tensor(0.2)\n",
    "\n",
    "# Indices of entries of X corresponding to each effect\n",
    "z_idx_p = [0, 1]\n",
    "z_idx_d = [2, 3]\n",
    "idx_obs = [False, True]\n",
    "latent_groups = [z_idx_p, z_idx_d]\n",
    "param_labels = [r\"$E \\ [Pa]$\", r\"$x_F [m]$\", r\"$\\mathrm{log}k_v [N/m]$\", r\"$T [C^o]$\"]\n",
    "\n",
    "mu_prior = torch.tensor([4.0, 0.5, 8.0, -4.0])\n",
    "sigma_prior = torch.tensor([0.5, 0.1, 1.0, 3.0])\n",
    "\n",
    "mu_gt = mu_prior\n",
    "sigma_gt = 0.1 * sigma_prior\n",
    "\n",
    "# Priors of physics-based latent variables\n",
    "dist_part_prior = dist.Normal(mu_prior[z_idx_p], sigma_prior[z_idx_p])\n",
    "dist_full_prior = dist.Normal(mu_prior, sigma_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c2e22-0e94-4c6c-80af-3290060d46ee",
   "metadata": {},
   "source": [
    "### Load data and surrogates of physics-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941ca20-025e-4ff3-93f9-0d63ef9f5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data, interpolate y\n",
    "X_full_load = torch.load(\"./data/X_beam.pt\")\n",
    "y_full_load = torch.load(\"./data/y_beam.pt\")\n",
    "X_part_load = torch.load(\"./data/X_beam_partial.pt\")\n",
    "y_part_load = torch.load(\"./data/y_beam_partial.pt\")\n",
    "\n",
    "# Load X\n",
    "X_full = X_full_load[1:]\n",
    "X_part = X_part_load[1:]\n",
    "\n",
    "y_full_raw = y_full_load[1:]\n",
    "y_part_raw = y_part_load[1:]\n",
    "coords = y_full_load[0]\n",
    "\n",
    "# Interpolate y\n",
    "f_full = scipy.interpolate.interp1d(coords.numpy(), y_full_raw.numpy())\n",
    "f_part = scipy.interpolate.interp1d(coords.numpy(), y_part_raw.numpy())\n",
    "y_full = torch.tensor(f_full(v.numpy()))\n",
    "y_part = torch.tensor(f_part(v.numpy()))\n",
    "\n",
    "# Scaling\n",
    "X_scaler_full = StandardScaler()\n",
    "X_scaler_full = X_scaler_full.fit(X_full)\n",
    "\n",
    "X_scaler_part = StandardScaler()\n",
    "X_scaler_part = X_scaler_part.fit(X_part)\n",
    "\n",
    "# loss\n",
    "loss_fn_train = nn.MSELoss()\n",
    "loss_fn_test = nn.MSELoss()\n",
    "\n",
    "# Models\n",
    "full_model = MLP(\n",
    "    nz_full,\n",
    "    nd_physics,\n",
    "    layers_nn_full,\n",
    "    input_transform=X_scaler_full,\n",
    "    nonlinear_last=None,\n",
    ")\n",
    "\n",
    "part_model = MLP(\n",
    "    nz_part,\n",
    "    nd_physics,\n",
    "    layers_nn_part,\n",
    "    input_transform=X_scaler_part,\n",
    "    nonlinear_last=None,\n",
    ")\n",
    "\n",
    "# Load pre-trained surrogates\n",
    "full_model.load_state_dict(torch.load(model_path + \"full_model\"))\n",
    "full_model.eval()\n",
    "\n",
    "part_model.load_state_dict(torch.load(model_path + \"part_model\"))\n",
    "part_model.eval()\n",
    "\n",
    "# Freeze models\n",
    "for param in full_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in part_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab09d59-339c-4d78-b48f-00fcd98914a9",
   "metadata": {},
   "source": [
    "### Synthetic data generation\n",
    "\n",
    "The synthetic measurements $\\boldsymbol{x}_{\\mathrm{meas}}$ are generated as follows:\n",
    "\n",
    "1. Samples are drawn from the ground truth distribution\n",
    "2. The full physics-based model is evaluated at the sampled points\n",
    "3. The model output is contaminated with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb281c-2235-43ee-8f9d-f283854976fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample inputs and outputs from the ground truth\n",
    "def generate_synthetic_data(n):\n",
    "    z_gt_sample = dist.Normal(mu_gt, sigma_gt).sample((n,))\n",
    "    x_sample = full_model(z_gt_sample)\n",
    "    x_sample += dist.Normal(0.0, sigma_meas).sample(x_sample.shape)\n",
    "    return z_gt_sample, x_sample\n",
    "\n",
    "z_gt, x_meas = generate_synthetic_data(n_data)\n",
    "z_gt_plot, x_meas_plot = generate_synthetic_data(n_plot)\n",
    "x_meas_plot_mean = x_meas_plot.mean(dim=0).detach()\n",
    "x_meas_plot_std = x_meas_plot.std(dim=0).detach()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(v, x_meas.T.detach().numpy(), color=\"blue\", linewidth=1.0)\n",
    "plt.plot(v, x_meas_plot_mean, color=\"red\")\n",
    "plt.fill_between(v, x_meas_plot_mean - 2 * x_meas_plot_std, x_meas_plot_mean + 2 * x_meas_plot_std, alpha=0.2, color=\"red\")\n",
    "plt.grid()\n",
    "plt.title(\"Measurements\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2918877-a40b-4466-8290-8b882bc40146",
   "metadata": {},
   "source": [
    "### Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe493223-ff74-4f34-b5b4-e34a4baeabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_encoder = GaussianEncoder(\n",
    "    n_latent=nz_full,\n",
    "    n_dim=nd_physics,\n",
    ")\n",
    "\n",
    "part_encoder = GaussianEncoder(\n",
    "    n_latent=nz_part,\n",
    "    n_dim=nd_physics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c44ab-67e9-4ce1-bb72-e98a492e1b36",
   "metadata": {},
   "source": [
    "### Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026cd446-925a-44a1-a0cd-1d7f837ada41",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_decoder = GaussianDecoder(full_model, sigma=None)\n",
    "part_decoder = GaussianDecoder(part_model, sigma=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d1f3fe-fb4a-40b5-bce4-965623dd29da",
   "metadata": {},
   "source": [
    "### Variational Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcccfd2-6a23-4864-94b4-bb8725963a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vae = VariationalInference(\n",
    "    full_encoder,\n",
    "    full_decoder,\n",
    "    dist_full_prior,\n",
    "    jitter=1e-6,\n",
    ")\n",
    "\n",
    "part_vae = VariationalInference(\n",
    "    part_encoder,\n",
    "    part_decoder,\n",
    "    dist_part_prior,\n",
    "    jitter=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd51c7-9a97-4466-91bb-64b6c9d91e2b",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84d13c-3755-4770-a64d-e39f0545b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_full_vec = []\n",
    "loss_part_vec = []\n",
    "optimizer_full = optim.Adam(full_vae.parameters(), lr=lr_vi)\n",
    "optimizer_part = optim.Adam(part_vae.parameters(), lr=lr_vi)\n",
    "\n",
    "pbar = trange(n_iter)\n",
    "for idx in pbar:\n",
    "    optimizer_full.zero_grad()\n",
    "    loss_full = full_vae.loss(x_meas, n=n_mc).sum() / (n_data * nd_physics)\n",
    "    loss_full.backward()\n",
    "    optimizer_full.step()\n",
    "    if idx % 100 == 0:\n",
    "        pbar.set_postfix(ELBO=loss_full.detach(), refresh=True)\n",
    "    loss_full_vec.append(loss_full.detach())\n",
    "\n",
    "pbar = trange(n_iter)\n",
    "for idx in pbar:\n",
    "    optimizer_part.zero_grad()\n",
    "    loss_part = part_vae.loss(x_meas, n=n_mc).sum() / (n_data * nd_physics)\n",
    "    loss_part.backward()\n",
    "    optimizer_part.step()\n",
    "    if idx % 100 == 0:\n",
    "        pbar.set_postfix(ELBO=loss_part.detach(), refresh=True)\n",
    "    loss_part_vec.append(loss_part.detach())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(0, n_iter), loss_full_vec, label=\"Full model loss\")\n",
    "plt.plot(range(0, n_iter), loss_part_vec, label=\"Partial model loss\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8983e299-0c38-4c01-ba8d-8e02db92f208",
   "metadata": {},
   "source": [
    "### Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631772ac-6f11-47e7-b053-4875b7d690b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample posterior predictive dist.\n",
    "x_pred_full, z_full_post, dens_z_full_post = full_vae.forward(None, n=n_plot)\n",
    "x_pred_part, z_part_post, dens_z_part_post = part_vae.forward(None, n=n_plot)\n",
    "z_full_post, dens_z_full_post = z_full_post.squeeze(1), dens_z_full_post.squeeze(1)\n",
    "z_part_post, dens_z_part_post = z_part_post.squeeze(1), dens_z_part_post.squeeze(1)\n",
    "\n",
    "# Get means and std. devs.\n",
    "mean_pred_full = torch.mean(x_pred_full.squeeze(1), dim=0).detach()\n",
    "mean_pred_part = torch.mean(x_pred_part.squeeze(1), dim=0).detach()\n",
    "\n",
    "sigma_pred_full = torch.std(x_pred_full.squeeze(1), dim=0).detach()\n",
    "sigma_pred_part = torch.std(x_pred_part.squeeze(1), dim=0).detach()\n",
    "\n",
    "# Ground truth\n",
    "z_gt_plot, x_gt_plot = generate_synthetic_data(n_plot)\n",
    "mean_gt_plot = torch.mean(x_gt_plot, dim=0).detach()\n",
    "sigma_gt_plot = torch.std(x_gt_plot, dim=0).detach()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 9))\n",
    "ax[0].plot(v, mean_pred_full, linestyle=\"dashed\", c=\"blue\")\n",
    "ax[0].fill_between(v, mean_pred_full - 2 * sigma_pred_full, mean_pred_full + 2 * sigma_pred_full, alpha=0.5, color=\"blue\")\n",
    "ax[0].set_title(\"Full physics model\")\n",
    "\n",
    "ax[1].plot(v, mean_pred_part, linestyle=\"dashed\", c=\"blue\", label=\"Mean pred.\")\n",
    "ax[1].fill_between(v, mean_pred_part - 2 * sigma_pred_part, mean_pred_part + 2 * sigma_pred_part, alpha=0.5, color=\"blue\", label=r\"$\\pm 2 \\sigma$\" + \" pred.\")\n",
    "ax[1].set_title(\"Partial physics model\")\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].plot(v, mean_gt_plot, c=\"red\", label=\"Mean g.t.\")\n",
    "    ax[i].fill_between(v, mean_gt_plot - 2 * sigma_gt_plot, mean_gt_plot + 2 * sigma_gt_plot, alpha=0.2, color=\"red\", label=r\"$\\pm 2 \\sigma$\" + \" g.t.\")\n",
    "    ax[i].grid()\n",
    "\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53f241-bc6f-452d-ae57-b378feea77e7",
   "metadata": {},
   "source": [
    "### Visualize latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1088ac0-da11-4eda-9e91-d9690a1adf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample prior\n",
    "z_part_prior = dist_part_prior.sample((n_plot,))\n",
    "z_full_prior = dist_full_prior.sample((n_plot,))\n",
    "\n",
    "# Plot prior and posterior for partial physics model\n",
    "df_part_prior = pd.DataFrame(z_part_prior.detach().numpy())\n",
    "df_part_prior.columns = [param_labels[z_idx_p[i]] for i in range(2)]\n",
    "df_part_prior.insert(0, \"type\", [\"Prior\"] * n_plot)\n",
    "df_part_post = pd.DataFrame(z_part_post.detach().numpy())\n",
    "df_part_post.columns = [param_labels[z_idx_p[i]] for i in range(2)]\n",
    "df_part_post.insert(0, \"type\", [\"Posterior\"] * n_plot)\n",
    "df_part_plot = pd.concat([df_part_prior, df_part_post])\n",
    "plot_part_latent = sns.pairplot(df_part_plot, hue=\"type\", kind=\"hist\")\n",
    "plot_part_latent.fig.suptitle(\"Partial physics model\")\n",
    "for i in range(nz_part):\n",
    "        plot_part_latent.axes[i, i].axvline(mu_gt[z_idx_p[i]], color=\"red\", linestyle=\"dashed\")\n",
    "plt.show()\n",
    "\n",
    "# Plot prior and posterior for full physics model\n",
    "df_full_prior = pd.DataFrame(z_full_prior.detach().numpy())\n",
    "df_full_prior.columns = param_labels\n",
    "df_full_prior.insert(0, \"type\", [\"Prior\"] * n_plot)\n",
    "df_full_post = pd.DataFrame(z_full_post.detach().numpy())\n",
    "df_full_post.columns = param_labels\n",
    "df_full_post.insert(0, \"type\", [\"Posterior\"] * n_plot)\n",
    "df_full_plot = pd.concat([df_full_prior, df_full_post])\n",
    "plot_full_latent = sns.pairplot(df_full_plot, hue=\"type\", kind=\"hist\")\n",
    "plot_full_latent.fig.suptitle(\"Full physics model\")\n",
    "for i in range(nz_full):\n",
    "        plot_full_latent.axes[i, i].axvline(mu_gt[i], color=\"red\", linestyle=\"dashed\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
